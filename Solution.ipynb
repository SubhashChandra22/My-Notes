{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If our data is Skewed\n",
    "def outlier_IQR(data,col):\n",
    "    IQR=data[col].quantile(.75)-data[col].quantile(.25)\n",
    "    lower_bridge=data[col].quantile(.25)-(IQR*1.5)\n",
    "    upper_bridge=data[col].quantile(.75)+(IQR*1.5)\n",
    "    return (lower_bridge,upper_bridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if our data is normally distributed \n",
    "def outlier_normally(df,col):\n",
    "     Lower_boundary=df[col].mean()*-3*df[col].std()\n",
    "     upper_boundary=df[col].mean()* +3*df[col].std()\n",
    "     return (Lower_boundary,upper_boundary) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example of outliers Treatment\n",
    "def replace_outlier(df,col):\n",
    "    IQR=df[col].quantile(.75)-df[col].quantile(.25)\n",
    "    lower_limit=df[col].quantile(.25)-(1.5*IQR)\n",
    "    upper_limit=df[col].quantile(.75)+(1.5*IQR)\n",
    "    non_outlier=np.where((df[col]<lower_limit )|(df[col]>upper_limit),df[col].median(),df[col])\n",
    "    df[col]=non_outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skewness Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## removing skewness\n",
    "from scipy import stats\n",
    "df['Diameter'],parameters=stats.boxcox(df['Diameter'])\n",
    "df['Length'],parameters=stats.boxcox(df['Length'])\n",
    "\n",
    "##Log transformation\n",
    "def log_transform(df,col):\n",
    "    df_1=df.copy()\n",
    "    if 0 in df_1[col].unique():\n",
    "        pass\n",
    "    else:\n",
    "        df_1[col]=np.log(df_1[col])\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.subplot(1,2,1)\n",
    "        stats.probplot(df_1[col],dist='norm',plot=pylab)\n",
    "        plt.subplot(1,2,2)\n",
    "        df[col].hist()\n",
    "        plt.title('log_transfer')\n",
    "##Reciprocal_transform\n",
    "def reciprocal_transform(df,col):\n",
    "    df_1=df.copy()\n",
    "    if 0 in df_1[col].unique():\n",
    "        pass\n",
    "    else:\n",
    "        df_1[col]=1/df_1[col]\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.subplot(1,2,1)\n",
    "        stats.probplot(df_1[col],dist='norm',plot=pylab)\n",
    "        plt.subplot(1,2,2)\n",
    "        df[col].hist()\n",
    "        plt.title('log_transfer')\n",
    "        \n",
    "## Log 1p transfromation\n",
    "def log1p_transform(df,col):\n",
    "    df_1=df.copy()\n",
    "    if 0 in df_1[col].unique():\n",
    "        pass\n",
    "    else:\n",
    "        df_1[col]=np.log1p(df_1[col])\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.subplot(1,2,1)\n",
    "        stats.probplot(df_1[col],dist='norm',plot=pylab)\n",
    "        plt.subplot(1,2,2)\n",
    "        df[col].hist()\n",
    "        plt.title('log_transfer')\n",
    "    \n",
    "##Exponential transformation Technique\n",
    "def exponential_transform(df,col):\n",
    "    df_1=df.copy()\n",
    "    if 0 in df_1[col].unique():\n",
    "        pass\n",
    "    else:\n",
    "        df_1[col]=df_1[col]**(1/1.2)\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.subplot(1,2,1)\n",
    "        stats.probplot(df_1[col],dist='norm',plot=pylab)\n",
    "        plt.subplot(1,2,2)\n",
    "        df[col].hist()\n",
    "        plt.title('log_transfer')\n",
    "        \n",
    "## Squareroot transformation\n",
    "def squareroot_transform(df,col):\n",
    "    df_1=df.copy()\n",
    "    if 0 in df_1[col].unique():\n",
    "        pass\n",
    "    else:\n",
    "        df_1[col]=np.sqrt(df_1[col])\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.subplot(1,2,1)\n",
    "        stats.probplot(df_1[col],dist='norm',plot=pylab)\n",
    "        plt.subplot(1,2,2)\n",
    "        df[col].hist()\n",
    "        plt.title('log_transfer')\n",
    "## cuberoot Transformation\n",
    "def cuberoot_transform(df,col):\n",
    "    df_1=df.copy()\n",
    "    if 0 in df_1[col].unique():\n",
    "        pass\n",
    "    else:\n",
    "        df_1[col]=np.cbrt(df_1[col])\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.subplot(1,2,1)\n",
    "        stats.probplot(df_1[col],dist='norm',plot=pylab)\n",
    "        plt.subplot(1,2,2)\n",
    "        df[col].hist()\n",
    "        plt.title('log_transfer')\n",
    "        \n",
    "##Boxcox transformation\n",
    "from scipy import stats\n",
    "def boxcox_transform(df,col):\n",
    "    df_1=df.copy()\n",
    "    if 0 in df_1[col].unique():\n",
    "        pass\n",
    "    else:\n",
    "        df_1[col],parameter=stats.boxcox(df_1[col])\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.subplot(1,2,1)\n",
    "        stats.probplot(df_1[col],dist='norm',plot=pylab)\n",
    "        plt.subplot(1,2,2)\n",
    "        df[col].hist()\n",
    "        plt.title('log_transfer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "selection=ExtraTreesClassifier()\n",
    "selection.fit(x,y)\n",
    "##use inbuilt class feature_importances of tree based classifiers\n",
    "print(selection.feature_importances_)\n",
    "# for plotting\n",
    "plt.figure(figsize=(15,6))\n",
    "feat_importances=pd.Series(selection.feature_importances_,index=x.columns)\n",
    "feat_importances.nlargest(30).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "covar_matrix=PCA(n_components=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Eigenvalues\n",
    "covar_matrix.fit(x)  ## x should be scaled\n",
    "variance = covar_matrix.explained_variance_ratio_ #calculate variance ratios\n",
    "\n",
    "var=np.cumsum(np.round(covar_matrix.explained_variance_ratio_, decimals=3)*100)\n",
    "var #cumulative sum of variance explained with [n] features\n",
    "## draw the graph\n",
    "plt.ylabel('% Variance Explained')\n",
    "plt.xlabel('# of Features')\n",
    "plt.title('PCA Analysis')\n",
    "plt.ylim(34,100.5)\n",
    "plt.style.context('seaborn-whitegrid')\n",
    "\n",
    "\n",
    "plt.plot(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing machine learning Library\n",
    "from sklearn.linear_model import LinearRegression,Lasso,Ridge,ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score,accuracy_score\n",
    "from sklearn.model_selection import cross_val_score,GridSearchCV,train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For regression\n",
    "def maxr2_score(clf,x,y):\n",
    "    maxr2_score1=0\n",
    "    for i in range(42,100):\n",
    "        x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.20,random_state=i)\n",
    "      ## incase of imbalanced dataset x_train_s,y_train_s=SMOTE().fit_resample(x_train,y_train)\n",
    "        clf.fit(x_train,y_train)\n",
    "        pred=clf.predict(x_test)\n",
    "        r2_cscore=r2_score(y_test,pred)\n",
    "        if r2_cscore>maxr2_score1:\n",
    "            maxr2_score1=r2_cscore\n",
    "            final_r=i\n",
    "    print('max r2 score corresponding to',final_r,'is',maxr2_score1)\n",
    "    print('cross validation score',cross_val_score(clf,x,y,scoring='r2').mean())\n",
    "    print('Standard Deviation',cross_val_score(clf,x,y,scoring='r2').std())\n",
    "    print('Training accuracy',clf.score(x_train,y_train))\n",
    "    print('Test Accuracy',clf.score(x_test,y_test))\n",
    "    print('MAE',mean_absolute_error(y_test,pred))\n",
    "    print('MSE',mean_squared_error(y_test,pred))\n",
    "    print('RMSE',np.sqrt(mean_squared_error(y_test,pred)))\n",
    "    \n",
    "    return final_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for classification\n",
    "def max_aucroc_score(clf,x,y):\n",
    "    maxroc_auc=0\n",
    "    for i in range(42,100):\n",
    "        x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.20,random_state=i,stratify=y)\n",
    "        x_train,y_train=SMOTE().fit_resample(x_train,y_train)\n",
    "        clf.fit(x_train,y_train)\n",
    "        pred=clf.predict(x_test)\n",
    "        roc_score=roc_auc_score(y_test,pred)\n",
    "        if roc_score>maxroc_auc:\n",
    "            maxroc_auc=roc_score\n",
    "            final_r=i\n",
    "    print('max Roc_auc score corresponding to',final_r,'is',maxroc_auc)\n",
    "    return final_r"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
