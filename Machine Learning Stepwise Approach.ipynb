{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0163cf1d",
   "metadata": {},
   "source": [
    "# Step-1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895ab6e2",
   "metadata": {},
   "source": [
    "# Importing Requried Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc29dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing Library\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "# Plot Style\n",
    "sns.set_context(\"paper\")\n",
    "style.use('fivethirtyeight')\n",
    "\n",
    "## Sklearn library\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import precision_score, recall_score,classification_report,accuracy_score,confusion_matrix,roc_auc_score,roc_curve,auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "## Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38793a8e",
   "metadata": {},
   "source": [
    "# Step-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81193fd5",
   "metadata": {},
   "source": [
    "# Setting up Jupyter View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231d757a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5b2532",
   "metadata": {},
   "source": [
    "# Step-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271a5d92",
   "metadata": {},
   "source": [
    "# Importing the Input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e908e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lead = pd.read_csv(\"Lead Scoring.csv\")\n",
    "lead.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5917057f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Inspect Dataframe\n",
    "\n",
    "#database dimension\n",
    "print(\"Database dimension     :\",lead.shape)\n",
    "print(\"Database size          :\",lead.size)\n",
    "print(\"Number of Row          :\",len(lead.index))\n",
    "print(\"Number of Columns      :\",len(lead.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb3c224",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking numerical columns statistics\n",
    "lead.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dc9502",
   "metadata": {},
   "outputs": [],
   "source": [
    "#info about the column types etc. \n",
    "lead.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8363a3",
   "metadata": {},
   "source": [
    "# Null Value Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc4368c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column wise Null Value calculate\n",
    "#Column wise null values in train data set \n",
    "null_perc = pd.DataFrame(round((lead.isnull().sum())*100/lead.shape[0],2)).reset_index()\n",
    "null_perc.columns = ['Column Name', 'Null Values Percentage']\n",
    "null_value = pd.DataFrame(lead.isnull().sum()).reset_index()\n",
    "null_value.columns = ['Column Name', 'Null Values']\n",
    "null_lead = pd.merge(null_value, null_perc, on='Column Name')\n",
    "null_lead.sort_values(\"Null Values\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f38d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column wise Null Value calculate\n",
    "#plotting the null value percentage\n",
    "sns.set_style(\"white\")\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "null_lead = pd.DataFrame((lead.isnull().sum())*100/lead.shape[0]).reset_index()\n",
    "ax = sns.pointplot(\"index\",0,data=null_lead)\n",
    "plt.xticks(rotation =90,fontsize =9)\n",
    "ax.axhline(45, ls='--',color='red')\n",
    "plt.title(\"Percentage of Missing values\")\n",
    "plt.ylabel(\"PERCENTAGE\")\n",
    "plt.xlabel(\"COLUMNS\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77921ed6",
   "metadata": {},
   "source": [
    "# Duplicate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c6c33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hint--- check for ID,columns\n",
    "print(\"Total number of duplicate values in Prospect ID column :\" , lead.duplicated(subset = 'Prospect ID').sum())\n",
    "print(\"Total number of duplicate values in Lead Number column :\" , lead.duplicated(subset = 'Lead Number').sum())\n",
    "print(\"Total number of duplicate values in Lead Origin column :\" , lead.duplicated(subset = 'Lead Origin').sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10eaa894",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706501c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop those column which contain more than 50% nulll values.\n",
    "\n",
    "## Drop those column which has zero duplicate values/ uniquness.\n",
    "\n",
    "## Drop the useless columns which are not requried in our Model Development\n",
    "\n",
    "## How to drop\n",
    "## Ex-\n",
    "cols_to_drop = ['Prospect ID','Lead Number','How did you hear about X Education','Lead Profile',\n",
    "                'Lead Quality','Asymmetrique Profile Score','Asymmetrique Activity Score',\n",
    "               'Asymmetrique Activity Index','Asymmetrique Profile Index','Tags','Last Notable Activity']\n",
    "\n",
    "## Dropping the unnecessary columns\n",
    "lead.drop(cols_to_drop,axis=1,inplace=True)\n",
    "lead.head()\n",
    "\n",
    "len(lead.columns)\n",
    "\n",
    "\n",
    "_______________________________________________________________________________________________________________________________\n",
    "\n",
    "## Tips\n",
    "## Replace values and Imputing codes\n",
    "lead['Lead Source'] = lead['Lead Source'].replace('google', 'Google')\n",
    "lead['Lead Source']=lead['Lead Source'].replace(np.nan,\"Email Opened\")\n",
    "lead['TotalVisits']=lead['TotalVisits'].fillna(lead['TotalVisits'].median())\n",
    "\n",
    "# Renaming some of the column headers which has long header\n",
    "lead.rename(columns={\"What is your current occupation\":'Occupation',\"A free copy of Mastering The Interview\":\"Free Copy\",\n",
    "                     \"Through Recommendations\":\"Recommendation\"},inplace=True)\n",
    "## Groupby\n",
    "top_10_happiest=df[:10].groupby('Country')['Happiness Rank'].max().sort_values(ascending=True)\n",
    "\n",
    "\n",
    "#Binning\n",
    "## MAking a group of tenure based of a Year\n",
    "Labels=[\"{0}-{1}\".format(i,i+11) for i in range(1,72,12)]\n",
    "\n",
    "df['tenure_group']=pd.cut(df['tenure'],range(1,80,12),right=False,labels=Labels)\n",
    "\n",
    "## Set a cutoff to convert multiclass class classification to Binary Class.\n",
    "bins=[2,6,9]\n",
    "labels=['Bad','Good']\n",
    "df_1['quality']=pd.cut(df_1['quality'],bins=bins,labels=labels)\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45faf14",
   "metadata": {},
   "source": [
    "# Segregating Categorical & Numerical Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c76031",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_col=lead.select_dtypes(exclude=['number']).columns.values\n",
    "numerical_col=lead.select_dtypes(include=['number']).columns.values\n",
    "\n",
    "\n",
    "print(\"Categorical Features:\\n{}\".format(categorical_col))\n",
    "print(\"Numerical Features:\\n{}\".format(numerical_col))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362762d6",
   "metadata": {},
   "source": [
    "# Categorical Column Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3f8f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Below Function will give You values,unique_values,null vaules, null_perent in  a dataframe###########\n",
    "def Cat_info(df,categorical_column):\n",
    "    df_result=pd.DataFrame(columns=[\"columns\",\"values\",\"unique_values\",\"null_values\",\"null_percent\"])\n",
    "    \n",
    "    df_temp=pd.DataFrame()\n",
    "    for value in categorical_column:\n",
    "        df_temp['columns']=[value]\n",
    "        df_temp['values']=[df[value].unique()]\n",
    "        df_temp[\"unique_values\"]=df[value].nunique()\n",
    "        df_temp[\"null_values\"] = df[value].isna().sum()\n",
    "        df_temp[\"null_percent\"] = (df[value].isna().sum()/len(df)*100).round(1)\n",
    "        df_result = df_result.append(df_temp)\n",
    "    df_result.sort_values(\"null_values\", ascending =False, inplace=True)\n",
    "    df_result.set_index(\"columns\", inplace=True)\n",
    "    return df_result\n",
    "####################\n",
    "df_cat = Cat_info(lead, categorical_col)\n",
    "df_cat\n",
    "\n",
    "## Hint:: We can check here catrgorical column with 1 unique values or multiple values and furter we can drop in our analysis\n",
    "\n",
    "# Appending the columns to col_to_drop where only 1 category value is present\n",
    "\n",
    "cols_to_drop = df_cat[df_cat['unique_values']==1].index.values.tolist() \n",
    "cols_to_drop\n",
    "\n",
    "#dropping unnecessary columns(Like unique values ==1)\n",
    "\n",
    "lead.drop(cols_to_drop, 1, inplace = True)\n",
    "len(lead.columns)  ## Here we dropped columns from our primary dataset\n",
    "\n",
    "## Again creating the categorical col and checking indepth analysis for Null values and Categorical Columns\n",
    "categorical_col = lead.select_dtypes(exclude =[\"number\"]).columns.values\n",
    "new_cat = Cat_info(lead, categorical_col)\n",
    "new_cat\n",
    "\n",
    "\n",
    "## Add on\n",
    "\n",
    "## Chekcing Value counts of all the object attributes.\n",
    "for col in obj_df:\n",
    "    print('--------------',col,'------------------------')\n",
    "    print(obj_df[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8b0839",
   "metadata": {},
   "source": [
    "# Null Values Handling in Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f835eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "(# Do this value counts for all the categorical Features)\n",
    "lead['City'].value_counts(normalize=True)*100 \n",
    "## Plotting the Value Counts\n",
    "style.use('fivethirtyeight')\n",
    "sns.countplot(lead['City'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "## Tips:-\n",
    "\n",
    "#1- In above null value percentage we can compare and we can't put Mode in every categorical null values.\n",
    "#2- If in any categorical column null values in more then 40 % then if we put Mode values, If will create a skewness.\n",
    "#3- In this case Either we can create a New Category and put that in place of null values \n",
    "lead['Specialization']=lead['Specialization'].replace(np.nan,\"Others\")\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.countplot(lead['Specialization'],palette = 'Set2')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()\n",
    "###\n",
    "#4- If we visualize or in value counts, then are values are more (90%) belong to one category, then we can consider\n",
    "#   it as a skewed. And We can drop it.\n",
    "#5-  While impute mode, we should always care that our feature should not be skewed. So choose wisely. Put any random 'category'.\n",
    "\n",
    "print(\"Number of null values present in Last Activity column is\",lead['Last Activity'].isnull().sum())\n",
    "print(\"Percentage of Null values present in Last Activity Columns is\",(lead['Last Activity'].isnull().sum())*100/lead.shape[0])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c142e622",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imputing most occuring value or Mode value\n",
    "\n",
    "lead['Last Activity']=lead['Last Activity'].replace(np.nan,\"Email Opened\")\n",
    "#or\n",
    "df['last Activity'] = df['Last Activity'].fillna(df['Last Activity'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c10566",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Again Checking null Values\n",
    "categorical_col = lead.select_dtypes(exclude =[\"number\"]).columns.values\n",
    "new_cat_null = Cat_info(lead, categorical_col)\n",
    "new_cat_null\n",
    "\n",
    "## This is final Stage for Categorical Feature columns\n",
    "#1- Make sure there is no missing values anymore\n",
    "#2- Check the unique values, replace if any spelling mistakes are present.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ea5e79",
   "metadata": {},
   "source": [
    "# Numerical Columns Null Value Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b43cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking unique values and null values for the numerical columns\n",
    "def Num_info(df, numeric_column):\n",
    "    df_result = pd.DataFrame(columns=[\"columns\",\"null_values\",\"null_percent\",\"Skewness\"])\n",
    "    \n",
    "    df_temp=pd.DataFrame()\n",
    "    for value in numeric_column:\n",
    "        df_temp[\"columns\"] = [value]\n",
    "        df_temp[\"Skewness\"] = df[value].skew()\n",
    "        df_temp[\"null_values\"] = df[value].isna().sum()\n",
    "        df_temp[\"null_percent\"] = (df[value].isna().sum()/len(df)*100).round(1)\n",
    "        df_result = df_result.append(df_temp)\n",
    "    \n",
    "    df_result.sort_values(\"null_values\", ascending =False, inplace=True)\n",
    "    df_result.set_index(\"columns\", inplace=True)\n",
    "    return df_result\n",
    "\n",
    "df_num = Num_info(lead,numerical_col)\n",
    "df_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e71420a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot this graph for all the features . This piece of code will give you KDE and Boxplot. Do it for all the columns\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(1,2,1)\n",
    "sns.distplot(lead['TotalVisits'])\n",
    "plt.subplot(1,2,2)\n",
    "sns.boxplot(lead['TotalVisits'])\n",
    "\n",
    "## Tips\n",
    "#1- If by seeing the in above data, we can deside. If outlier are present then impute median value in place of missing values.\n",
    "lead['TotalVisits']=lead['TotalVisits'].fillna(lead['TotalVisits'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7a0179",
   "metadata": {},
   "source": [
    "# 5. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb80a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For target column( category and Imbalance Check)\n",
    "labels = 'No','Yes'\n",
    "lead['Converted'].astype(str).value_counts().plot(kind='pie',\n",
    "                            figsize=(10, 6),\n",
    "                            autopct='%1.1f%%', \n",
    "                            startangle=90,    \n",
    "                            shadow=True,       \n",
    "                            labels=None,                                \n",
    "                            )\n",
    "\n",
    "plt.title('Distribution of Lead Approval', y=1.12) \n",
    "plt.axis('equal') \n",
    "# add legend\n",
    "plt.legend(labels=labels, loc='upper left') \n",
    " # show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee13b364",
   "metadata": {},
   "source": [
    "# Univariate Analysis - Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b929e08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_lead=lead[lead['Converted']==1]\n",
    "fail_lead=lead[lead['Converted']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54d86b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This Function will Give a good comparision if we have binary class classifiaction(churn/Not)\n",
    "def univariate_categorical(column):\n",
    "    check=pd.DataFrame()\n",
    "    check['Total Leads']=lead[column].value_counts()\n",
    "    check['Qualified Lead']=converted_lead[column].value_counts()\n",
    "    check['Non Qualified Lead']=fail_lead[column].value_counts()\n",
    "    check[\"% Lead Converted\"]=round(check['Qualified Lead']*100/check['Total Leads'],2)\n",
    "    check=check.fillna(0)\n",
    "    #check.columns=['Leads','Total Leads','Qualified Lead',\"Non Qualify Lead\",\"% Lead Converted\"]\n",
    "    check.reset_index(inplace=True)## \n",
    "    check=check.rename(columns={\"index\":column})\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(15,8))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title(column)\n",
    "    plt.xticks(rotation = 90)\n",
    "    sns.countplot(lead[column],hue=lead['Converted'])\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title(\"% of Lead Conversion\")\n",
    "    plt.xticks(rotation = 90)\n",
    "    sns.barplot(x=check[column],y=check['% Lead Converted'],data=lead)\n",
    "                                           \n",
    "    return check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e972c4f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc05d367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d49ba69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "813f2e7b",
   "metadata": {},
   "source": [
    "# Numerical Column for Outliers Treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b134604",
   "metadata": {},
   "source": [
    "# Multiple Box plot and Distributon plot for Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f571aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "### How to plot multiple distribution plot##\n",
    "plt.figure(figsize=(18,10))\n",
    "plot=1\n",
    "for col in num_df:\n",
    "    if plot<=6:\n",
    "        plt.subplot(2,3,plot)\n",
    "        sns.distplot(df[col],color='red')\n",
    "        plt.xlabel(col)\n",
    "        plot=plot+1\n",
    "plt.show()\n",
    "\n",
    "## For boxplot\n",
    "\n",
    "plt.figure(figsize=(18,10))\n",
    "plot=1\n",
    "for col in num_df:\n",
    "    if plot<=6:\n",
    "        plt.subplot(2,3,plot)\n",
    "        sns.boxplot(df[col],color='green')\n",
    "        plt.xlabel(col)\n",
    "        plot=plot+1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48143d81",
   "metadata": {},
   "source": [
    "# Outliers Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f29224",
   "metadata": {},
   "outputs": [],
   "source": [
    "## when data is normally distributed.(IQR Methood). Best Approach\n",
    "def replace_outlier(df,col):\n",
    "    IQR=df[col].quantile(.75)-df[col].quantile(.25)\n",
    "    lower_limit=df[col].quantile(.25)-(1.5*IQR)\n",
    "    upper_limit=df[col].quantile(.75)+(1.5*IQR)\n",
    "    non_outlier=np.where((df[col]<lower_limit )|(df[col]>upper_limit),df[col].median(),df[col])\n",
    "    df[col]=non_outlier\n",
    "    plt.subplot(1,2,1)\n",
    "    sns.distplot(df[col])\n",
    "    plt.subplot(1,2,2)\n",
    "    sns.boxplot(df[col])\n",
    "    \n",
    "## If our data is Skewed (Quantile Method)\n",
    "def outlier_IQR(data,col):\n",
    "    IQR=data[col].quantile(.75)-data[col].quantile(.25)\n",
    "    lower_bridge=data[col].quantile(.25)-(IQR*1.5)\n",
    "    upper_bridge=data[col].quantile(.75)+(IQR*1.5)\n",
    "    return (lower_bridge,upper_bridge)\n",
    "\n",
    "# if our data is normally distributed \n",
    "def outlier_normally(df,col):\n",
    "     Lower_boundary=df[col].mean()*-3*df[col].std()\n",
    "     upper_boundary=df[col].mean()* +3*df[col].std()\n",
    "     return (Lower_boundary,upper_boundary) \n",
    "    \n",
    "    \n",
    "#Example of outliers Treatment\n",
    "def replace_outlier(df,col):\n",
    "    IQR=df[col].quantile(.75)-df[col].quantile(.25)\n",
    "    lower_limit=df[col].quantile(.25)-(1.5*IQR)\n",
    "    upper_limit=df[col].quantile(.75)+(1.5*IQR)\n",
    "    non_outlier=np.where((df[col]<lower_limit )|(df[col]>upper_limit),df[col].median(),df[col])\n",
    "    df[col]=non_outlier\n",
    "    \n",
    "    \n",
    "#replotting the graphs to check for outlier treatment\n",
    "i=1\n",
    "plt.figure(figsize=[16,8])\n",
    "for col in numerical_col:\n",
    "    plt.subplot(2,2,i)\n",
    "    sns.boxplot(y=lead[col])\n",
    "    plt.title(col)\n",
    "    plt.ylabel('')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac27a43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Again  Checking the null values \n",
    "numerical_col = lead.select_dtypes(include=[\"number\"]).columns.values\n",
    "new_num_null = Num_info(lead, numerical_col)\n",
    "new_num_null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bd063a",
   "metadata": {},
   "source": [
    "# Skewness Check and removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4f70bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## removing skewness\n",
    "from scipy import stats\n",
    "df['Diameter'],parameters=stats.boxcox(df['Diameter'])\n",
    "df['Length'],parameters=stats.boxcox(df['Length'])\n",
    "\n",
    "##Log transformation\n",
    "def log_transform(df,col):\n",
    "    df_1=df.copy()\n",
    "    if 0 in df_1[col].unique():\n",
    "        pass\n",
    "    else:\n",
    "        df_1[col]=np.log(df_1[col])\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.subplot(1,2,1)\n",
    "        stats.probplot(df_1[col],dist='norm',plot=pylab)\n",
    "        plt.subplot(1,2,2)\n",
    "        df[col].hist()\n",
    "        plt.title('log_transfer')\n",
    "##Reciprocal_transform\n",
    "def reciprocal_transform(df,col):\n",
    "    df_1=df.copy()\n",
    "    if 0 in df_1[col].unique():\n",
    "        pass\n",
    "    else:\n",
    "        df_1[col]=1/df_1[col]\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.subplot(1,2,1)\n",
    "        stats.probplot(df_1[col],dist='norm',plot=pylab)\n",
    "        plt.subplot(1,2,2)\n",
    "        df[col].hist()\n",
    "        plt.title('log_transfer')\n",
    "        \n",
    "## Log 1p transfromation\n",
    "def log1p_transform(df,col):\n",
    "    df_1=df.copy()\n",
    "    if 0 in df_1[col].unique():\n",
    "        pass\n",
    "    else:\n",
    "        df_1[col]=np.log1p(df_1[col])\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.subplot(1,2,1)\n",
    "        stats.probplot(df_1[col],dist='norm',plot=pylab)\n",
    "        plt.subplot(1,2,2)\n",
    "        df[col].hist()\n",
    "        plt.title('log_transfer')\n",
    "    \n",
    "##Exponential transformation Technique\n",
    "def exponential_transform(df,col):\n",
    "    df_1=df.copy()\n",
    "    if 0 in df_1[col].unique():\n",
    "        pass\n",
    "    else:\n",
    "        df_1[col]=df_1[col]**(1/1.2)\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.subplot(1,2,1)\n",
    "        stats.probplot(df_1[col],dist='norm',plot=pylab)\n",
    "        plt.subplot(1,2,2)\n",
    "        df[col].hist()\n",
    "        plt.title('log_transfer')\n",
    "        \n",
    "## Squareroot transformation\n",
    "def squareroot_transform(df,col):\n",
    "    df_1=df.copy()\n",
    "    if 0 in df_1[col].unique():\n",
    "        pass\n",
    "    else:\n",
    "        df_1[col]=np.sqrt(df_1[col])\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.subplot(1,2,1)\n",
    "        stats.probplot(df_1[col],dist='norm',plot=pylab)\n",
    "        plt.subplot(1,2,2)\n",
    "        df[col].hist()\n",
    "        plt.title('log_transfer')\n",
    "## cuberoot Transformation\n",
    "def cuberoot_transform(df,col):\n",
    "    df_1=df.copy()\n",
    "    if 0 in df_1[col].unique():\n",
    "        pass\n",
    "    else:\n",
    "        df_1[col]=np.cbrt(df_1[col])\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.subplot(1,2,1)\n",
    "        stats.probplot(df_1[col],dist='norm',plot=pylab)\n",
    "        plt.subplot(1,2,2)\n",
    "        df[col].hist()\n",
    "        plt.title('log_transfer')\n",
    "        \n",
    "##Boxcox transformation\n",
    "from scipy import stats\n",
    "def boxcox_transform(df,col):\n",
    "    df_1=df.copy()\n",
    "    if 0 in df_1[col].unique():\n",
    "        pass\n",
    "    else:\n",
    "        df_1[col],parameter=stats.boxcox(df_1[col])\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.subplot(1,2,1)\n",
    "        stats.probplot(df_1[col],dist='norm',plot=pylab)\n",
    "        plt.subplot(1,2,2)\n",
    "        df[col].hist()\n",
    "        plt.title('log_transfer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdfd484",
   "metadata": {},
   "outputs": [],
   "source": [
    "lead=lead.replace({\"Yes\": 1, \"No\":0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4419b83d",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a450be6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## One Hot Encoding\n",
    "lead=pd.get_dummies(lead,columns=['Lead Origin','Lead Source','Last Activity','Specialization','Occupation'],drop_first=True)\n",
    "\n",
    "## Label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    " le=LabelEncoder()\n",
    "for col in lead.columns:\n",
    "    if lead[col].dtype=='object':\n",
    "         lead[col]=le.fit_transform(lead[col])\n",
    "            \n",
    "## target Encoding\n",
    "import category_encoders as ce\n",
    "encoder=ce.TargetEncoder()\n",
    "for col in lead.columns:\n",
    "    if lead[col].dtype=='object':\n",
    "        lead[col]=encoder.fit_transform(lead[col],lead['Converted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d181ba",
   "metadata": {},
   "source": [
    "# HeatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b97c8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the data using heatmap to check Correlation\n",
    "plt.figure(figsize=[15,15])\n",
    "sns.heatmap(lead.corr(), cmap=\"RdYlGn\",linewidth =1)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "## Correlation bar plot\n",
    "lead.corr()['Converted'].sort_values(ascending=False).drop(['Converted']).plot.bar(figsize=(10,6),grid=True,title='Correlation With target',fontsize=15)\n",
    "\n",
    "\n",
    "#or\n",
    "\n",
    "## Correlation with Happiness score\n",
    "df.corr()['Happiness Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad17d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Most Postitive Correlated \n",
    "corr_lead = lead.corr()\n",
    "corr_lead = corr_lead.where(np.triu(np.ones(corr_lead.shape),k=1).astype(np.bool))\n",
    "corr_df = corr_lead.unstack().reset_index()\n",
    "corr_df.columns =['VAR1','VAR2','Correlation']\n",
    "corr_df.dropna(subset = [\"Correlation\"], inplace = True) \n",
    "corr_df.sort_values(by='Correlation', ascending=False, inplace=True)\n",
    "\n",
    "# Top 5 Positive correlated variables\n",
    "corr_df.head(5)\n",
    "\n",
    "\n",
    "corr_df.sort_values(by='Correlation', ascending=True, inplace=True)\n",
    "\n",
    "# Top 5 Negatively correlated variables\n",
    "corr_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c9f44d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67077bc1",
   "metadata": {},
   "source": [
    "# Train - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7621da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target variable\n",
    "Y = lead['Converted']\n",
    "X = lead.drop(['Converted'], axis=1)\n",
    "\n",
    "\n",
    "# Splitting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=0.7, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b50f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the shape of the created Train & Test DFs\n",
    "print(\" Shape of X_train is : \",X_train.shape)\n",
    "print(\" Shape of y_train is : \",y_train.shape)\n",
    "print(\" Shape of X_test is  : \",X_test.shape)\n",
    "print(\" Shape of y_test is  : \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054176ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Alternative\n",
    "\n",
    "# Creating a test set X_test, then X_valid becomes our validation set\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X, y, train_size=0.8, random_state=42)\n",
    "X_test, X_valid, y_test, y_valid = train_test_split(X_rem, y_rem, test_size=0.5)\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, criterion=\"entropy\", random_state=0)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('****Results****')\n",
    "train_predictions = rf.predict(X_valid)\n",
    "acc = accuracy_score(y_valid, train_predictions)\n",
    "print(classification_report(train_predictions, y_valid))\n",
    "print(\"Accuracy: {:.4%}\".format(acc))\n",
    "\n",
    "## Predicting on Unseen Data\n",
    "print('****Results****')\n",
    "train_predictions = rf.predict(X_test)\n",
    "acc = accuracy_score(y_test, train_predictions)\n",
    "print(classification_report(train_predictions, y_test))\n",
    "print(\"Accuracy: {:.4%}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87a88e4",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aef190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data normalization with sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# fit scaler on training data\n",
    "ss = StandardScaler().fit(X_train)\n",
    "\n",
    "# transform training data\n",
    "X_train_norm = ss.transform(X_train)\n",
    "\n",
    "# transform testing dataabs\n",
    "X_test_norm = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d411f47",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf40af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##This Method we can we can use in case of Multicollinearity \n",
    "\n",
    "## Referecne : https://www.youtube.com/watch?v=FndwYNcVe0U&list=PLZoTAELRMXVPgjwJ8VyRoqmfNs2CJwhVH&index=2\n",
    "\n",
    "import seaborn as sns\n",
    "#Using Pearson Correlation\n",
    "plt.figure(figsize=(12,10))\n",
    "cor = X_train.corr()\n",
    "sns.heatmap(cor, annot=True, cmap=plt.cm.CMRmap_r)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# with the following function we can select highly correlated features\n",
    "# it will remove the first feature that is correlated with anything other feature\n",
    "\n",
    "def correlation(dataset, threshold):   ## In dataset only Put X_train\n",
    "    col_corr = set()  # Set of all the names of correlated columns\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
    "                colname = corr_matrix.columns[i]  # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "    return col_corr\n",
    "\n",
    "## to get number of highly correlated columns\n",
    "corr_features = correlation(X_train, 0.7)\n",
    "len(set(corr_features))\n",
    "\n",
    "## Getting the names of the particular correlated features\n",
    "corr_features\n",
    "\n",
    "\n",
    "## Dropping from X_train and Y_train. After dropping , mmodel is ready to build.\n",
    "X_train.drop(corr_features,axis=1)\n",
    "X_test.drop(corr_features,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98a6fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3-Feature Selection-Information gain - mutual information In Classification Problem Statements\n",
    "## Importing the library\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "# determine the mutual information\n",
    "mutual_info = mutual_info_classif(X_train, y_train)\n",
    "mutual_info\n",
    "\n",
    "##Getting values\n",
    "mutual_info = pd.Series(mutual_info)\n",
    "mutual_info.index = X_train.columns\n",
    "mutual_info.sort_values(ascending=False)\n",
    "\n",
    "###let's plot the ordered mutual_info values per feature\n",
    "mutual_info.sort_values(ascending=False).plot.bar(figsize=(20, 8))\n",
    "\n",
    "## Selecting the k best parameters\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "#No we Will select the  top 5 important features\n",
    "sel_five_cols = SelectKBest(mutual_info_classif, k=5)\n",
    "sel_five_cols.fit(X_train, y_train)\n",
    "X_train.columns[sel_five_cols.get_support()]\n",
    "\n",
    "\n",
    "## The output columns of this will help me to select the columns for our model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb32f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Selection-Information gain - mutual information In Regression Problem Statements\n",
    "\n",
    "##Code-1\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "# determine the mutual information\n",
    "mutual_info = mutual_info_regression(X_train, y_train)\n",
    "mutual_info\n",
    "\n",
    "## Code-2\n",
    "mutual_info = pd.Series(mutual_info)\n",
    "mutual_info.index = X_train.columns\n",
    "mutual_info.sort_values(ascending=False)\n",
    "\n",
    "##Code-3\n",
    "\n",
    "mutual_info.sort_values(ascending=False).plot.bar(figsize=(15,5))\n",
    "\n",
    "#Code-4\n",
    "#No we Will select the  top 5 important features\n",
    "sel_five_cols = SelectKBest(mutual_info_classif, k=5)\n",
    "sel_five_cols.fit(X_train, y_train)\n",
    "X_train.columns[sel_five_cols.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b517bfae",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6ae7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "model=ExtraTreesClassifier()\n",
    "model.fit(X,y)\n",
    "\n",
    "\n",
    "print(model.feature_importances_)\n",
    "\n",
    "\n",
    "ranked_features=pd.Series(model.feature_importances_,index=X.columns)\n",
    "\n",
    "ranked_features.nlargest(10).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5653bffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ef2495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2372ac6",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e7b1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "covar_matrix=PCA(n_components=34)\n",
    "\n",
    "\n",
    "#Calculate Eigenvalues\n",
    "covar_matrix.fit(x)  ## x should be scaled\n",
    "variance = covar_matrix.explained_variance_ratio_ #calculate variance ratios\n",
    "\n",
    "var=np.cumsum(np.round(covar_matrix.explained_variance_ratio_, decimals=3)*100)\n",
    "var #cumulative sum of variance explained with [n] features\n",
    "## draw the graph\n",
    "plt.ylabel('% Variance Explained')\n",
    "plt.xlabel('# of Features')\n",
    "plt.title('PCA Analysis')\n",
    "plt.ylim(34,100.5)\n",
    "plt.style.context('seaborn-whitegrid')\n",
    "\n",
    "\n",
    "plt.plot(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddddd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA(n_components=\"Based on above graph stagnation point\")\n",
    "x=pca.fit_transform(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f9413d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a794d94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3b970d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89b72808",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906290ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For Classification\n",
    "score=[]\n",
    "f_1=[]\n",
    "CV_score=[]\n",
    "model_name=[]\n",
    "SD=[]\n",
    "def best_model(clf):\n",
    "    clf.fit(X_train_norm,y_train)\n",
    "    print(clf)\n",
    "    print('Trainng Score:',clf.score(X_train_norm,y_train))\n",
    "    print('Testing score:',clf.score(X_test_norm,y_test))\n",
    "    pred=clf.predict(X_test_norm)\n",
    "    print('Accuracy_score',accuracy_score(y_test,pred))\n",
    "    print('F1 score',f1_score(y_test,pred))\n",
    "    print('cross validation score',cross_val_score(clf,X,Y,scoring='accuracy').mean())\n",
    "    print('Standard Deviation',cross_val_score(clf,X,Y,scoring='accuracy').std())\n",
    "    print('confusion matrix',confusion_matrix(y_test,pred))\n",
    "    print('\\n')\n",
    "    print('Classification Report',classification_report(y_test,pred))\n",
    "    print('---'*20)\n",
    "    print('Roc_auc Score',roc_auc_score(y_test,pred))\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,pred)\n",
    "    roc_auc = auc( false_positive_rate, true_positive_rate)\n",
    "    plt.plot(false_positive_rate, true_positive_rate,label = \"AUC = %0.2f\"% roc_auc)\n",
    "    plt.plot([0,1],[0,1],'r--')\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.ylabel(\"True positive rate\")\n",
    "    plt.xlabel(\"False positive rate\")\n",
    "    print(\"\\n\\n\")\n",
    "    score.append(accuracy_score(y_test,pred))\n",
    "    CV_score.append(cross_val_score(clf,X,Y,scoring='accuracy').mean())\n",
    "    f_1.append(f1_score(y_test,pred))\n",
    "    SD.append(cross_val_score(clf,X,Y,scoring='accuracy').std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72803bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For imbalance dataset\n",
    "\n",
    "## Over sampling our data\n",
    "sm = SMOTEENN()\n",
    "X_resampled1, y_resampled1 = sm.fit_resample(x,y)  ## Where X is Independent features and Y is dependent Features\n",
    "\n",
    "def max_accuracy_score(clf,x,y):\n",
    "    max_accuracy=0\n",
    "    for i in range(42,100):\n",
    "        x_train,x_test,y_train,y_test=train_test_split(X_resampled1,y_resampled1,test_size=.20,random_state=i,stratify=y_resampled1)\n",
    "    ##over sampling of our Data\n",
    "       # print(x_train.shape,y_train.shape) \n",
    "        clf.fit(x_train,y_train)\n",
    "        pred=clf.predict(x_test)\n",
    "        accuracy_check=accuracy_score(y_test,pred)\n",
    "        if accuracy_check>max_accuracy:\n",
    "            max_accuracy=accuracy_check\n",
    "            final_r=i\n",
    "    print('max accuracy score corresponding to',final_r,'is',max_accuracy)\n",
    "    print('\\n')\n",
    "    print('cross validation score',cross_val_score(clf,x,y,scoring='accuracy').mean())\n",
    "    print('\\n')\n",
    "    print('Standard Deviation',cross_val_score(clf,x,y,scoring='accuracy').std())\n",
    "    print('\\n')\n",
    "    print('F1 score',f1_score(y_test,pred))\n",
    "    print('\\n')\n",
    "    print('Training accuracy',clf.score(x_train,y_train))\n",
    "    print('\\n')\n",
    "    print('Test Accuracy',clf.score(x_test,y_test))\n",
    "    print('\\n')\n",
    "    print('Confusion Matrix',confusion_matrix(y_test,pred))\n",
    "    print('\\n')\n",
    "    print('Classification Report',classification_report(y_test,pred))\n",
    "    print('\\n')\n",
    "    print('Roc_auc Score',roc_auc_score(y_test,pred))\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,pred)\n",
    "    roc_auc = auc( false_positive_rate, true_positive_rate)\n",
    "    plt.plot(false_positive_rate, true_positive_rate,label = \"AUC = %0.2f\"% roc_auc)\n",
    "    plt.plot([0,1],[0,1],'r--')\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.ylabel(\"True positive rate\")\n",
    "    plt.xlabel(\"False positive rate\")\n",
    "    print(\"\\n\\n\")\n",
    "    return final_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41763ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### For regression\n",
    "def maxr2_score(clf,x,y):\n",
    "    maxr2_score1=0\n",
    "    for i in range(42,100):\n",
    "        x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.20,random_state=i)\n",
    "      ## incase of imbalanced dataset x_train_s,y_train_s=SMOTE().fit_resample(x_train,y_train)\n",
    "        clf.fit(x_train,y_train)\n",
    "        pred=clf.predict(x_test)\n",
    "        r2_cscore=r2_score(y_test,pred)\n",
    "        if r2_cscore>maxr2_score1:\n",
    "            maxr2_score1=r2_cscore\n",
    "            final_r=i\n",
    "    print('max r2 score corresponding to',final_r,'is',maxr2_score1)\n",
    "    print('cross validation score',cross_val_score(clf,x,y,scoring='r2').mean())\n",
    "    print('Standard Deviation',cross_val_score(clf,x,y,scoring='r2').std())\n",
    "    print('Training accuracy',clf.score(x_train,y_train))\n",
    "    print('Test Accuracy',clf.score(x_test,y_test))\n",
    "    print('MAE',mean_absolute_error(y_test,pred))\n",
    "    print('MSE',mean_squared_error(y_test,pred))\n",
    "    print('RMSE',np.sqrt(mean_squared_error(y_test,pred)))\n",
    "    \n",
    "    return final_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b9e6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LogisticRegression()\n",
    "best_model(lr)\n",
    "\n",
    "rf=RandomForestClassifier()\n",
    "best_model(rf)\n",
    "\n",
    "dt=DecisionTreeClassifier()\n",
    "best_model(dt)\n",
    "\n",
    "nb=GaussianNB()\n",
    "best_model(nb)\n",
    "\n",
    "knn=KNeighborsClassifier()\n",
    "best_model(knn)\n",
    "\n",
    "\n",
    "svc=SVC()\n",
    "best_model(svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ad159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Final=pd.DataFrame()\n",
    "Final['Model']=['LogisticRegression','DecisionTreeClassifier','SVC','KNeighborsClassifier','GaussianNB','RandomForestClassifier']\n",
    "\n",
    "Final[\"Accuracy Score\"]=score\n",
    "Final['Cross Val']=CV_score\n",
    "Final['Standard Deviation']=SD\n",
    "Final['Diff']=Final[\"Accuracy Score\"]-Final['Cross Val']\n",
    "Final['F_1 Score']=f_1\n",
    "Final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2784943c",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b677cc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_1=LogisticRegression()\n",
    "param={'penalty':['l2','l1','elasticnet'],'C':[.001,.01,.1,1,10],'solver':['newton-cg','lbfgs','liblinear','sag','saga'],'max_iter':[50,100,200]}\n",
    "\n",
    "grid=GridSearchCV(estimator=lg_1,param_grid=param,scoring='accuracy',n_jobs=-1)\n",
    "\n",
    "grid.fit(X_train_norm,y_train)\n",
    "\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3732c038",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgm=LogisticRegression(C=10,max_iter=200,penalty='l1',solver='saga')\n",
    "lgm.fit(X_train_norm,y_train)\n",
    "pred=lgm.predict(X_test_norm)\n",
    "print('Final Accuracy_score :',accuracy_score(pred,y_test))\n",
    "print('\\n')\n",
    "print('Final f_1 score :',f1_score(pred,y_test))\n",
    "print('\\n')\n",
    "print('Final roc_auc score :',roc_auc_score(pred,y_test))\n",
    "print('\\n')\n",
    "print('Final classification Report :',classification_report(pred,y_test))\n",
    "print('\\n')\n",
    "print('Final confusion Matrix :',confusion_matrix(pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480d8684",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b97c5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename='LeadScoring'\n",
    "pickle.dump(lgm,open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf2d464",
   "metadata": {},
   "source": [
    "# Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a05759",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model=pickle.load(open(filename,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e72029",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.score(X_test_norm,y_test)\n",
    "\n",
    "loaded_model.predict_proba([[]])\n",
    "\n",
    "loaded_model.predict([values1,values2,values3,.....])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
